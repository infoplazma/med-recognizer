## **Техническое задание: Pipeline по структурированию метаданных для медицинских чанков**

---

### **1. Цели пайплайна**

* Автоматически структурировать текстовые данные медицинских документов в виде набора чанков с богатыми метаданными.
* Обеспечить последующую релевантную индексацию, disease-centric retrieval, explainability и возможность построения связей между фрагментами.
* Использовать возможности локальной LLM для извлечения сложных сущностей и семантических связей, максимально используя её контекстное окно.

---

### **2. Общая архитектура пайплайна**

**Вход**:

* Оцифрованный медицинский текст (PDF/Docx/plain text)
* Массив документов (`docs`), каждый документ имеет хотя бы `"text"` и `"metadata"` (имя файла, страница и пр.)

**Выход**:

* Массив чанков (словари), каждый из которых снабжён:

  * `"id_"`: уникальный идентификатор
  * `"diseases"`: список disease/diagnosis для чанка
  * `"linked_diagnoses"`: словарь “название заболевания → id соседнего чанка с этим заболеванием”
  * `"chunk_summary"`: краткое описание чанка (4–10 слов, search-focused)
  * `"section_titles"`: список актуальных заголовков разделов (по ходу документа)
  * `"chunk_index"`, `"file_name"`, `"page"` — служебные поля для поиска и explainability

---

### **3. Шаги пайплайна**

**3.1. Chunking**

* Каждый документ разбивается на чанки длиной \~700 токенов (желательно sentence-aware, но можно просто по длине, overlap 50–100 токенов).
* Для каждого чанка сохраняется его текст, порядковый номер, позиция, исходный файл и страница.

**3.2. Извлечение заголовков**

* С помощью регулярки или (если неявные заголовки) с помощью LLM:

  * Извлечь все возможные section titles (например, "Diagnosis", "Symptoms", "Clinical presentation" и т.д.) по всему документу.
  * Для каждого чанка определить, какие актуальные section titles применимы (обычно ближайшие “выше по тексту”).

**3.3. Определение заболеваний (“diseases”)**

* Для каждого чанка с помощью LLM определяется список заболеваний/диагнозов, которые в нём обсуждаются.

  * Промпт: “What diseases or diagnoses are mentioned or discussed in the following text? Reply with a comma-separated list, or 'None' if none.”

**3.4. Краткое summary чанка**

* Для каждого чанка получить через LLM 1‑2 предложения/фразы (“chunk\_summary”), релевантные поиску.

**3.5. Построение связей (“linked\_diagnoses”)**

* Для каждого чанка, если disease/diagnosis найдены:

  * Идём к предыдущему/следующему чанку и проверяем через LLM/по списку disease, есть ли общие диагнозы.
  * В поле `"linked_diagnoses"` записываем для каждого найденного disease название и id соответствующего чанка.

**3.6. Итоговая сборка**

* Каждый чанк сериализуется в dict с нужными полями.

---

### **4. Используемые технологии**

* **LLM** (Llama3-Med42-8B через LM Studio, OpenAI API-compatible endpoint)
* **Chunking**: стандартные sentence splitters, либо простое по токенам
* **Регулярные выражения** или LLM для поиска section titles
* **Chain-of-prompts**: современные LangChain-подходы (PromptTemplate | LLM | postprocess)

---

### **5. Технические рекомендации**

* Каждый этап структурирования должен быть **идемпотентным** и сериализуемым (в dict/json).
* Код пайплайна должен позволять запускать каждый шаг отдельно, для дебага и быстрой доработки.
* Все поля метаданных должны быть легко расширяемыми (чтобы при необходимости можно было добавить, например, `"symptoms"`, `"analyses"` и др.).

---

### **6. Пример структуры чанка**

```python
{
    "id_": 101,
    "diseases": ["Campylobacteriosis", "Covid 19"],
    "linked_diagnoses": {
        "Campylobacteriosis": 100,
        "Covid 19": 102
    },
    "chunk_summary": "PCR-based diagnosis of Campylobacter and Covid 19",
    "section_titles": ["Infectious diseases", "Diagnosis"],
    "chunk_index": 10,
    "file_name": "medical_article_42.pdf",
    "page": 7
}
```

---

## **Аргументация**

* Такой pipeline позволяет строить disease-centric поиск, а также реализовать explainable AI/IR — пользователь увидит не просто кусок текста, а его “место” и “роль” в медицинском знании.
* Гибкая архитектура позволяет расширять pipeline под новые задачи (поиск симптомов, анализов и др.) и легко менять параметры (chunk size, тип связей и т.д.).
* Максимально используется контекстное окно и сила локальной LLM, без избыточных затрат (всё работает батчами, можно легко кешировать результаты).

---

## **Далее**

* После этого ТЗ можно перейти к коду — реализовать функции chunking, extraction, disease-linking, summary-generation и postprocess.
* Если захочешь — могу расписать архитектуру модулей и предложить структуру файлов проекта для максимально чистой разработки.

---

**Если нужен пример кода по каждому шагу — просто скажи, выдам пошагово!**

### Приблизительная структура

- project-root/
    - README.md
    - requirements.txt
    - .env
    - data/
        - med_sources/
        - ...
    - storage/
        - ...
    - notebooks/
        - exploratory.ipynb
    - utils/
        - __init__.py
        - timing.py
        - formatting.py
        - ... (другие утилиты)
    - med_index/
        - __init__.py
        - config.py
        - chunking/
            - __init__.py
            - splitter.py
            - utils.py
        - extraction/
            - __init__.py
            - disease.py
            - section_titles.py
            - summary.py
        - linking/
            - __init__.py
            - diagnoses.py
        - metadata/
            - __init__.py
            - builder.py
        - index/
            - __init__.py
            - build.py
        - retrieval/
            - __init__.py
            - query.py
        - main.py
        - pipeline.py
    - tests/
        - ...
    - docs/
        - pipeline.md
